{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The University of Melbourne, School of Computing and Information Systems\n",
    "# COMP30027 Machine Learning, 2022 Semester 1\n",
    "\n",
    "## Assignment 2: Sentiment Classification of Tweets\n",
    "\n",
    "This is a sample code to assist you with vectorising the 'Train' dataset for your assignment 2.\n",
    "\n",
    "First we read the CSV datafiles (Train and Test)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21802 15261 6541\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>805582613687713000</td>\n",
       "      <td>doctors hit campaign trail as race to medical...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>637480203497832000</td>\n",
       "      <td>is anybody going to the radio station tomorro...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>641096279930507000</td>\n",
       "      <td>i just found out naruto didn't become the 5th...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>625730917647126000</td>\n",
       "      <td>\"prince george reservist who died saturday ju...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>633292370906230000</td>\n",
       "      <td>season in the sun versi nirvana rancak gak..s...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15256</th>\n",
       "      <td>19596</td>\n",
       "      <td>625891517274701000</td>\n",
       "      <td>\"#cubs beat #rockies 9-8 on kris bryant's wal...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15257</th>\n",
       "      <td>19597</td>\n",
       "      <td>641364140947148000</td>\n",
       "      <td>dr. roseen will be in h3 tomorrow at 12:30p p...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15258</th>\n",
       "      <td>19598</td>\n",
       "      <td>636993524911763000</td>\n",
       "      <td>\"@ happy amelemshaty hahahahhahahaha, kan hyb...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15259</th>\n",
       "      <td>19599</td>\n",
       "      <td>620722821870829000</td>\n",
       "      <td>\"@michael22418062 watchman was the 1st draft ...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15260</th>\n",
       "      <td>19601</td>\n",
       "      <td>681419250217664000</td>\n",
       "      <td>\"tony blair's labour may have seemed 'moderat...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15261 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0                  id  \\\n",
       "0               2  805582613687713000   \n",
       "1               3  637480203497832000   \n",
       "2               4  641096279930507000   \n",
       "3               5  625730917647126000   \n",
       "4               6  633292370906230000   \n",
       "...           ...                 ...   \n",
       "15256       19596  625891517274701000   \n",
       "15257       19597  641364140947148000   \n",
       "15258       19598  636993524911763000   \n",
       "15259       19599  620722821870829000   \n",
       "15260       19601  681419250217664000   \n",
       "\n",
       "                                                    text sentiment  \n",
       "0       doctors hit campaign trail as race to medical...   neutral  \n",
       "1       is anybody going to the radio station tomorro...  positive  \n",
       "2       i just found out naruto didn't become the 5th...   neutral  \n",
       "3       \"prince george reservist who died saturday ju...   neutral  \n",
       "4       season in the sun versi nirvana rancak gak..s...  positive  \n",
       "...                                                  ...       ...  \n",
       "15256   \"#cubs beat #rockies 9-8 on kris bryant's wal...   neutral  \n",
       "15257   dr. roseen will be in h3 tomorrow at 12:30p p...   neutral  \n",
       "15258   \"@ happy amelemshaty hahahahhahahaha, kan hyb...   neutral  \n",
       "15259   \"@michael22418062 watchman was the 1st draft ...   neutral  \n",
       "15260   \"tony blair's labour may have seemed 'moderat...   neutral  \n",
       "\n",
       "[15261 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15261</th>\n",
       "      <td>19602</td>\n",
       "      <td>679602563478614000</td>\n",
       "      <td>gardai fear a split in the ira and sinn fein?...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15262</th>\n",
       "      <td>19603</td>\n",
       "      <td>637460573811277000</td>\n",
       "      <td>psa i am stealing shawn tomorrow night. he wi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15263</th>\n",
       "      <td>19604</td>\n",
       "      <td>802014331235921000</td>\n",
       "      <td>fastpowerpunch movesbowieaction notfastest #i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15264</th>\n",
       "      <td>19605</td>\n",
       "      <td>802161345294647000</td>\n",
       "      <td>@paulboy the make-up free=fresh face look- so...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15265</th>\n",
       "      <td>19606</td>\n",
       "      <td>802380028549828000</td>\n",
       "      <td>electing to ‚äòopt out‚äù of obamacare : john...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21797</th>\n",
       "      <td>27896</td>\n",
       "      <td>805677750363095000</td>\n",
       "      <td>@hrtablaze the beginning of a dictatorship is ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21798</th>\n",
       "      <td>27897</td>\n",
       "      <td>637854813930196000</td>\n",
       "      <td>son idc anymore. i'm going by shawn tomorrow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21799</th>\n",
       "      <td>27898</td>\n",
       "      <td>802374277047656000</td>\n",
       "      <td>but remember the clinton foundation?? https://...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21800</th>\n",
       "      <td>27899</td>\n",
       "      <td>640441306494296000</td>\n",
       "      <td>press: \"r u worried murray dominated his 3rd r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21801</th>\n",
       "      <td>27900</td>\n",
       "      <td>638666306015789000</td>\n",
       "      <td>@rinashah i have been using moto g 2nd gen for...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6541 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0                  id  \\\n",
       "15261       19602  679602563478614000   \n",
       "15262       19603  637460573811277000   \n",
       "15263       19604  802014331235921000   \n",
       "15264       19605  802161345294647000   \n",
       "15265       19606  802380028549828000   \n",
       "...           ...                 ...   \n",
       "21797       27896  805677750363095000   \n",
       "21798       27897  637854813930196000   \n",
       "21799       27898  802374277047656000   \n",
       "21800       27899  640441306494296000   \n",
       "21801       27900  638666306015789000   \n",
       "\n",
       "                                                    text  \n",
       "15261   gardai fear a split in the ira and sinn fein?...  \n",
       "15262   psa i am stealing shawn tomorrow night. he wi...  \n",
       "15263   fastpowerpunch movesbowieaction notfastest #i...  \n",
       "15264   @paulboy the make-up free=fresh face look- so...  \n",
       "15265   electing to ‚äòopt out‚äù of obamacare : john...  \n",
       "...                                                  ...  \n",
       "21797  @hrtablaze the beginning of a dictatorship is ...  \n",
       "21798       son idc anymore. i'm going by shawn tomorrow  \n",
       "21799  but remember the clinton foundation?? https://...  \n",
       "21800  press: \"r u worried murray dominated his 3rd r...  \n",
       "21801  @rinashah i have been using moto g 2nd gen for...  \n",
       "\n",
       "[6541 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15261</th>\n",
       "      <td>679602563478614000</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15262</th>\n",
       "      <td>637460573811277000</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15263</th>\n",
       "      <td>802014331235921000</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15264</th>\n",
       "      <td>802161345294647000</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15265</th>\n",
       "      <td>802380028549828000</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21797</th>\n",
       "      <td>805677750363095000</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21798</th>\n",
       "      <td>637854813930196000</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21799</th>\n",
       "      <td>802374277047656000</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21800</th>\n",
       "      <td>640441306494296000</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21801</th>\n",
       "      <td>638666306015789000</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6541 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       id sentiment\n",
       "15261  679602563478614000  negative\n",
       "15262  637460573811277000   neutral\n",
       "15263  802014331235921000  negative\n",
       "15264  802161345294647000  positive\n",
       "15265  802380028549828000   neutral\n",
       "...                   ...       ...\n",
       "21797  805677750363095000  negative\n",
       "21798  637854813930196000   neutral\n",
       "21799  802374277047656000   neutral\n",
       "21800  640441306494296000   neutral\n",
       "21801  638666306015789000  positive\n",
       "\n",
       "[6541 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "negative\n"
     ]
    }
   ],
   "source": [
    "# This code block partitions Train.csv for holdout\n",
    "# If a code block doen't work simply run all and it should reset variables\n",
    "# kernel used is base (Python 3.9.7)\n",
    "# Code used has been adapted from practicals\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "train_data_full = pd.read_csv(\"Train.csv\", sep=',')\n",
    "\n",
    "trainrows = int(0.7*len(train_data_full))\n",
    "testrows = int(0.3*len(train_data_full))+1\n",
    "\n",
    "print(len(train_data_full),trainrows,testrows)\n",
    "\n",
    "train_data = pd.read_csv(\"Train.csv\", sep=',', nrows=trainrows)\n",
    "\n",
    "trainevaldata = pd.read_csv(\"Train.csv\", sep=',')\n",
    "evaldata = trainevaldata.iloc[trainrows:trainrows+testrows, :-1]\n",
    "evalanswers = trainevaldata.iloc[trainrows:trainrows+testrows, [1,-1]]\n",
    "\n",
    "test_data = pd.read_csv(\"Test.csv\", sep=',', nrows=5)\n",
    "\n",
    "display(train_data)\n",
    "display(evaldata)\n",
    "display(evalanswers)\n",
    "\n",
    "#print(\"\\n\")\n",
    "\n",
    "print(evalanswers.iloc[2,-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train length: 15261\n",
      "Test length: 6541\n"
     ]
    }
   ],
   "source": [
    "# This code block extracts the features and class labels\n",
    "\n",
    "#separating instance and label for Train\n",
    "X_train_raw = [x[0] for x in train_data[['text']].values]\n",
    "Y_train = [x[0] for x in train_data[['sentiment']].values]\n",
    "\n",
    "#check the result\n",
    "print(\"Train length:\",len(X_train_raw))\n",
    "\n",
    "#separating instance and label for Test\n",
    "#X_test_raw = [x[0] for x in test_data[['text']].values]\n",
    "X_test_raw = [x[0] for x in evaldata[['text']].values]\n",
    "Y_test = [x[0] for x in evalanswers[['sentiment']].values]\n",
    "\n",
    "#check the result\n",
    "print(\"Test length:\",len(X_test_raw))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========= one-r\n",
      "BoW accuracy is: 0.6462314630790399\n",
      "tfidf accuracy is: 0.6460785812566886\n"
     ]
    }
   ],
   "source": [
    "# This code block is for playing around with BoW and tfidf accuracies\n",
    "\n",
    "# BoW vs tfidf\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "BoW_vectorizer = CountVectorizer(ngram_range=(1,1), strip_accents='ascii', lowercase=True)\n",
    "\n",
    "#Build the feature set (vocabulary) and vectorise the Train dataset using BoW\n",
    "X_train_BoW = BoW_vectorizer.fit_transform(X_train_raw)\n",
    "\n",
    "#Use the feature set (vocabulary) from Train to vectorise the Test dataset \n",
    "X_test_BoW = BoW_vectorizer.transform(X_test_raw)\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(strip_accents='ascii', ngram_range=(1,1), lowercase=True)\n",
    "\n",
    "#Build the feature set (vocabulary) and vectorise the Tarin dataset using TFIDF\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train_raw)\n",
    "\n",
    "#Use the feature set (vocabulary) from Train to vectorise the Test dataset \n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test_raw)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "models = [#GaussianNB(),\n",
    "          #MultinomialNB(),\n",
    "          DecisionTreeClassifier(max_depth=1),\n",
    "          #KNeighborsClassifier(n_neighbors=200),\n",
    "          #DecisionTreeClassifier(max_depth=None),\n",
    "          #LogisticRegression(max_iter = 500),\n",
    "          #SVC(kernel='rbf', gamma=0.7),\n",
    "          #SVC(kernel='linear')\n",
    "          ]\n",
    "titles = [#'GNB',\n",
    "          #'MNB',\n",
    "          'one-r',\n",
    "          #'5-nearest neighbour',\n",
    "          #'Decision Tree',\n",
    "          #'Logistic Regression',\n",
    "          #'SVM with a cubic kernel',\n",
    "          #'SVM with an RBF kernel'\n",
    "          ]\n",
    "\n",
    "\n",
    "Xs = [(X_train_BoW, X_test_BoW), (X_train_tfidf, X_test_tfidf)]\n",
    "X_names = ['BoW', 'tfidf']\n",
    "for title, model in zip(titles, models):\n",
    "    print('\\n=========',title)\n",
    "    for X_name, X in zip(X_names, Xs):\n",
    "        X_train_t, X_test_t = X\n",
    "        model.fit(X_train_t, Y_train)\n",
    "        y_test_predict = model.predict(X_test_t)\n",
    "        accuracy =  accuracy_score(Y_test, y_test_predict)\n",
    "        print(X_name, 'accuracy is:',  accuracy)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========= one-r\n",
      "tfidf accuracy is: 0.6460785812566886\n",
      "one-r Accuracy: 0.5852214898947931\n"
     ]
    }
   ],
   "source": [
    "# One R\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(strip_accents='ascii', ngram_range=(1,1), lowercase=True)\n",
    "\n",
    "#Build the feature set (vocabulary) and vectorise the Tarin dataset using TFIDF\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train_raw)\n",
    "\n",
    "#Use the feature set (vocabulary) from Train to vectorise the Test dataset \n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test_raw)\n",
    "\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import numpy as np\n",
    "\n",
    "models = [DecisionTreeClassifier(max_depth=1),]\n",
    "titles = ['one-r']\n",
    "\n",
    "XX = [x[0] for x in train_data_full[['text']].values]\n",
    "yy = [x[0] for x in train_data_full[['sentiment']].values]\n",
    "XX = tfidf_vectorizer.fit_transform(XX)\n",
    "\n",
    "# Holdout score\n",
    "Xs = [(X_train_tfidf, X_test_tfidf)]\n",
    "X_names = ['tfidf']\n",
    "for title, model in zip(titles, models):\n",
    "    print('\\n=========',title)\n",
    "    for X_name, X in zip(X_names, Xs):\n",
    "        X_train_t, X_test_t = X\n",
    "        model.fit(X_train_t, Y_train)\n",
    "        y_test_predict = model.predict(X_test_t)\n",
    "        accuracy =  accuracy_score(Y_test, y_test_predict)\n",
    "        print(X_name, 'accuracy is:',  accuracy)\n",
    "\n",
    "# Cross validation score\n",
    "for title, model in zip(titles, models):\n",
    "    acc = np.mean(cross_val_score(model, XX, yy, cv=5))\n",
    "    print(title, \"Accuracy:\",acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------------------------- K =  10 ------------------------------\n",
      "\n",
      "========= MNB (with k= 10 features): \n",
      "BoW accuracy is: 0.66243693624828\n",
      "x2 accuracy is: 0.6526524996177955\n",
      "\n",
      "--------------------------------------- K =  50 ------------------------------\n",
      "\n",
      "========= MNB (with k= 50 features): \n",
      "BoW accuracy is: 0.66243693624828\n",
      "x2 accuracy is: 0.6563216633542271\n",
      "\n",
      "--------------------------------------- K =  100 ------------------------------\n",
      "\n",
      "========= MNB (with k= 100 features): \n",
      "BoW accuracy is: 0.66243693624828\n",
      "x2 accuracy is: 0.6518880905060388\n",
      "\n",
      "--------------------------------------- K =  200 ------------------------------\n",
      "\n",
      "========= MNB (with k= 200 features): \n",
      "BoW accuracy is: 0.66243693624828\n",
      "x2 accuracy is: 0.6479131631249044\n",
      "\n",
      "--------------------------------------- K =  500 ------------------------------\n",
      "\n",
      "========= MNB (with k= 500 features): \n",
      "BoW accuracy is: 0.66243693624828\n",
      "x2 accuracy is: 0.6228405442592876\n",
      "\n",
      "--------------------------------------- K =  750 ------------------------------\n",
      "\n",
      "========= MNB (with k= 750 features): \n",
      "BoW accuracy is: 0.66243693624828\n",
      "x2 accuracy is: 0.6171839168322887\n",
      "\n",
      "--------------------------------------- K =  1000 ------------------------------\n",
      "\n",
      "========= MNB (with k= 1000 features): \n",
      "BoW accuracy is: 0.66243693624828\n",
      "x2 accuracy is: 0.6142791622076135\n"
     ]
    }
   ],
   "source": [
    "# This code block is for playing around with BoW\n",
    "\n",
    "# BoW\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "models = [#GaussianNB(),\n",
    "          MultinomialNB(),\n",
    "          #DecisionTreeClassifier(max_depth=1),\n",
    "          #KNeighborsClassifier(n_neighbors=20),\n",
    "          #DecisionTreeClassifier(max_depth=10),\n",
    "          #LogisticRegression(max_iter = 1000),\n",
    "          #SVC(kernel='rbf', gamma=0.7),\n",
    "          #SVC(kernel='linear')\n",
    "          ]\n",
    "titles = [#'GNB',\n",
    "          'MNB',\n",
    "          #'one-r',\n",
    "          #'5-nearest neighbour',\n",
    "          #'Decision Tree',\n",
    "          #'Logistic Regression',\n",
    "          #'SVM with a rbf kernel',\n",
    "          #'SVM with an linear kernel'\n",
    "          ]\n",
    "\n",
    "k = 1000\n",
    "\n",
    "for k in [10,50,100,200,500,750,1000]:\n",
    "    print('\\n--------------------------------------- K = ', k,'------------------------------')\n",
    "    x2 = SelectKBest(chi2, k=k)\n",
    "    x2.fit(X_train_BoW,Y_train)\n",
    "    X_train_x2 = x2.transform(X_train_BoW)\n",
    "    X_test_x2 = x2.transform(X_test_BoW)\n",
    "\n",
    "\n",
    "    Xs = [(X_train_BoW, X_test_BoW),(X_train_x2, X_test_x2)]\n",
    "    X_names = ['BoW', 'x2']\n",
    "    for title, model in zip(titles, models):\n",
    "        print('\\n=========',title, '(with k=',k,'features): ')\n",
    "        for X_name, X in zip(X_names, Xs):\n",
    "            X_train_t, X_test_t = X\n",
    "            model.fit(X_train_t, Y_train)\n",
    "            y_test_predict = model.predict(X_test_t)\n",
    "            accuracy =  accuracy_score(Y_test, y_test_predict)\n",
    "            print(X_name, 'accuracy is:',  accuracy)\n",
    "\n",
    "    \n",
    "    #(X_train_BoW, X_test_BoW),\n",
    "    #'BoW',\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------------------------- K =  10 ------------------------------\n",
      "\n",
      "========= 5-nearest neighbour (with k= 10 features): \n",
      "tfidf accuracy is: 0.640574835652041\n",
      "x2 accuracy is: 0.6517352086836875\n",
      "\n",
      "--------------------------------------- K =  50 ------------------------------\n",
      "\n",
      "========= 5-nearest neighbour (with k= 50 features): \n",
      "tfidf accuracy is: 0.640574835652041\n",
      "x2 accuracy is: 0.6554043724201193\n",
      "\n",
      "--------------------------------------- K =  100 ------------------------------\n",
      "\n",
      "========= 5-nearest neighbour (with k= 100 features): \n",
      "tfidf accuracy is: 0.640574835652041\n",
      "x2 accuracy is: 0.6602965907353615\n",
      "\n",
      "--------------------------------------- K =  200 ------------------------------\n",
      "\n",
      "========= 5-nearest neighbour (with k= 200 features): \n",
      "tfidf accuracy is: 0.640574835652041\n",
      "x2 accuracy is: 0.6618254089588748\n",
      "\n",
      "--------------------------------------- K =  500 ------------------------------\n",
      "\n",
      "========= 5-nearest neighbour (with k= 500 features): \n",
      "tfidf accuracy is: 0.640574835652041\n",
      "x2 accuracy is: 0.6616725271365235\n",
      "\n",
      "--------------------------------------- K =  750 ------------------------------\n",
      "\n",
      "========= 5-nearest neighbour (with k= 750 features): \n",
      "tfidf accuracy is: 0.640574835652041\n",
      "x2 accuracy is: 0.6602965907353615\n",
      "\n",
      "--------------------------------------- K =  1000 ------------------------------\n",
      "\n",
      "========= 5-nearest neighbour (with k= 1000 features): \n",
      "tfidf accuracy is: 0.640574835652041\n",
      "x2 accuracy is: 0.6613667634918208\n"
     ]
    }
   ],
   "source": [
    "# This code block is for playing around with tfidf\n",
    "\n",
    "# tfidf\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "models = [#GaussianNB(),\n",
    "          #MultinomialNB(),\n",
    "          #DecisionTreeClassifier(max_depth=1),\n",
    "          KNeighborsClassifier(n_neighbors=20),\n",
    "          #DecisionTreeClassifier(),\n",
    "          #LogisticRegression(max_iter = 1000),\n",
    "          #SVC(kernel='rbf', gamma=0.7),\n",
    "          #SVC(kernel='linear')\n",
    "          ]\n",
    "titles = [#'GNB',\n",
    "          #'MNB',\n",
    "          #'one-r',\n",
    "          '5-nearest neighbour',\n",
    "          #'Decision Tree',\n",
    "          #'Logistic Regression',\n",
    "          #'SVM with a rbf kernel',\n",
    "          #'SVM with an linear kernel'\n",
    "          ]\n",
    "\n",
    "k = 1000\n",
    "\n",
    "for k in [10,50,100,200,500,750,1000]:\n",
    "    print('\\n--------------------------------------- K = ', k,'------------------------------')\n",
    "    x2 = SelectKBest(chi2, k=k)\n",
    "    x2.fit(X_train_tfidf,Y_train)\n",
    "    X_train_x2 = x2.transform(X_train_tfidf)\n",
    "    X_test_x2 = x2.transform(X_test_tfidf)\n",
    "\n",
    "\n",
    "    #mi = SelectKBest(score_func=mutual_info_classif, k=k)\n",
    "    #mi.fit(X_train_tfidf,Y_train)\n",
    "    #X_train_mi = mi.transform(X_train_tfidf)\n",
    "    #X_test_mi = mi.transform(X_test_tfidf)\n",
    "\n",
    "\n",
    "    Xs = [(X_train_tfidf, X_test_tfidf), (X_train_x2, X_test_x2)]\n",
    "    X_names = ['tfidf', 'x2']\n",
    "    for title, model in zip(titles, models):\n",
    "        print('\\n=========',title, '(with k=',k,'features): ')\n",
    "        for X_name, X in zip(X_names, Xs):\n",
    "            X_train_t, X_test_t = X\n",
    "            model.fit(X_train_t, Y_train)\n",
    "            y_test_predict = model.predict(X_test_t)\n",
    "            accuracy =  accuracy_score(Y_test, y_test_predict)\n",
    "            print(X_name, 'accuracy is:',  accuracy)\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MNB BoW accuracy is: 0.6708454364776029\n",
      "[[ 114  754   27]\n",
      " [ 114 3769  384]\n",
      " [   5  869  505]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.49      0.13      0.20       895\n",
      "     neutral       0.70      0.88      0.78      4267\n",
      "    positive       0.55      0.37      0.44      1379\n",
      "\n",
      "    accuracy                           0.67      6541\n",
      "   macro avg       0.58      0.46      0.47      6541\n",
      "weighted avg       0.64      0.67      0.63      6541\n",
      "\n",
      "['neutral' 'neutral' 'neutral' ... 'neutral' 'neutral' 'neutral']\n",
      "MNB Accuracy: 0.635308205129284\n"
     ]
    }
   ],
   "source": [
    "# MultinomialNB BoW\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "BoW_vectorizer = CountVectorizer(ngram_range=(1,2), strip_accents='ascii', lowercase=False)\n",
    "\n",
    "#Build the feature set (vocabulary) and vectorise the Train dataset using BoW\n",
    "X_train_BoW = BoW_vectorizer.fit_transform(X_train_raw)\n",
    "\n",
    "#Use the feature set (vocabulary) from Train to vectorise the Test dataset \n",
    "X_test_BoW = BoW_vectorizer.transform(X_test_raw)\n",
    "\n",
    "models = [MultinomialNB(alpha=1,fit_prior=True)]\n",
    "titles = ['MNB']\n",
    "\n",
    "mnbpredictions = []\n",
    "\n",
    "Xs = [(X_train_BoW, X_test_BoW)]\n",
    "X_names = ['BoW']\n",
    "for title, model in zip(titles, models):\n",
    "    for X_name, X in zip(X_names, Xs):\n",
    "        X_train_t, X_test_t = X\n",
    "        model.fit(X_train_t, Y_train)\n",
    "        y_test_predict = model.predict(X_test_t)\n",
    "        #print(y_test_predict)\n",
    "        mnbpredictions = y_test_predict\n",
    "        accuracy =  accuracy_score(Y_test, y_test_predict)\n",
    "        print(title,X_name, 'accuracy is:',  accuracy)\n",
    "        print(confusion_matrix(Y_test, y_test_predict, labels=[\"negative\", \"neutral\", \"positive\"]))\n",
    "        print(classification_report(Y_test, y_test_predict, labels=[\"negative\", \"neutral\", \"positive\"]))\n",
    "\n",
    "print(mnbpredictions)\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import numpy as np\n",
    "\n",
    "XX = [x[0] for x in train_data_full[['text']].values]\n",
    "yy = [x[0] for x in train_data_full[['sentiment']].values]\n",
    "XX = BoW_vectorizer.fit_transform(XX)\n",
    "\n",
    "\n",
    "for title, model in zip(titles, models):\n",
    "    acc = np.mean(cross_val_score(model, XX, yy, cv=5))\n",
    "    print(title, \"Accuracy:\",acc)\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression tfidf accuracy is: 0.6656474545176578\n",
      "[[ 293  554   48]\n",
      " [ 342 3365  560]\n",
      " [  19  664  696]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.45      0.33      0.38       895\n",
      "     neutral       0.73      0.79      0.76      4267\n",
      "    positive       0.53      0.50      0.52      1379\n",
      "\n",
      "    accuracy                           0.67      6541\n",
      "   macro avg       0.57      0.54      0.55      6541\n",
      "weighted avg       0.65      0.67      0.66      6541\n",
      "\n",
      "['neutral' 'positive' 'neutral' ... 'neutral' 'neutral' 'positive']\n",
      "Logistic Regression Accuracy: 0.6659012956795956\n"
     ]
    }
   ],
   "source": [
    "# Logistic regression tfidf\n",
    "\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(strip_accents='ascii', ngram_range=(1,1), lowercase=True)\n",
    "\n",
    "#Build the feature set (vocabulary) and vectorise the Tarin dataset using TFIDF\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train_raw)\n",
    "\n",
    "#Use the feature set (vocabulary) from Train to vectorise the Test dataset \n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test_raw)\n",
    "\n",
    "models = [LogisticRegression(max_iter = 1000,multi_class='multinomial',solver='saga',C=1,penalty='l1')]\n",
    "titles = ['Logistic Regression',]\n",
    "\n",
    "logisticpredictions = []\n",
    "\n",
    "Xs = [(X_train_tfidf, X_test_tfidf)]\n",
    "X_names = ['tfidf']\n",
    "for title, model in zip(titles, models):\n",
    "    for X_name, X in zip(X_names, Xs):\n",
    "        X_train_t, X_test_t = X\n",
    "        model.fit(X_train_t, Y_train)\n",
    "        y_test_predict = model.predict(X_test_t)\n",
    "        logisticpredictions = y_test_predict\n",
    "        accuracy =  accuracy_score(Y_test, y_test_predict)\n",
    "        print(title,X_name, 'accuracy is:',  accuracy)\n",
    "        print(confusion_matrix(Y_test, y_test_predict, labels=[\"negative\", \"neutral\", \"positive\"]))\n",
    "        print(classification_report(Y_test, y_test_predict, labels=[\"negative\", \"neutral\", \"positive\"]))\n",
    "\n",
    "print(logisticpredictions)\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import numpy as np\n",
    "\n",
    "XX = [x[0] for x in train_data_full[['text']].values]\n",
    "yy = [x[0] for x in train_data_full[['sentiment']].values]\n",
    "XX = tfidf_vectorizer.fit_transform(XX)\n",
    "\n",
    "\n",
    "for title, model in zip(titles, models):\n",
    "    acc = np.mean(cross_val_score(model, XX, yy, cv=5))\n",
    "    print(title, \"Accuracy:\",acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM with an linear kernel tfidf accuracy is: 0.6696223818987922\n",
      "[[ 292  565   38]\n",
      " [ 337 3418  512]\n",
      " [  27  682  670]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.45      0.33      0.38       895\n",
      "     neutral       0.73      0.80      0.77      4267\n",
      "    positive       0.55      0.49      0.52      1379\n",
      "\n",
      "    accuracy                           0.67      6541\n",
      "   macro avg       0.58      0.54      0.55      6541\n",
      "weighted avg       0.65      0.67      0.66      6541\n",
      "\n",
      "['neutral' 'positive' 'neutral' ... 'neutral' 'neutral' 'positive']\n",
      "SVM with an linear kernel Accuracy: 0.671084182358646\n"
     ]
    }
   ],
   "source": [
    "# SVM tfidf\n",
    "\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(strip_accents='ascii', ngram_range=(1,1), lowercase=True)\n",
    "\n",
    "#Build the feature set (vocabulary) and vectorise the Tarin dataset using TFIDF\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train_raw)\n",
    "\n",
    "#Use the feature set (vocabulary) from Train to vectorise the Test dataset \n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test_raw)\n",
    "\n",
    "models = [SVC(kernel='sigmoid',decision_function_shape='ovo',C=1,gamma='scale')]\n",
    "titles = ['SVM with an linear kernel']\n",
    "\n",
    "svmpredictions = []\n",
    "\n",
    "Xs = [(X_train_tfidf, X_test_tfidf)]\n",
    "X_names = ['tfidf']\n",
    "for title, model in zip(titles, models):\n",
    "    for X_name, X in zip(X_names, Xs):\n",
    "        X_train_t, X_test_t = X\n",
    "        model.fit(X_train_t, Y_train)\n",
    "        y_test_predict = model.predict(X_test_t)\n",
    "        svmpredictions = y_test_predict\n",
    "        accuracy =  accuracy_score(Y_test, y_test_predict)\n",
    "        print(title,X_name, 'accuracy is:',  accuracy)\n",
    "        print(confusion_matrix(Y_test, y_test_predict, labels=[\"negative\", \"neutral\", \"positive\"]))\n",
    "        print(classification_report(Y_test, y_test_predict, labels=[\"negative\", \"neutral\", \"positive\"]))\n",
    "\n",
    "print(svmpredictions)\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import numpy as np\n",
    "\n",
    "XX = [x[0] for x in train_data_full[['text']].values]\n",
    "yy = [x[0] for x in train_data_full[['sentiment']].values]\n",
    "XX = tfidf_vectorizer.fit_transform(XX)\n",
    "\n",
    "\n",
    "for title, model in zip(titles, models):\n",
    "    acc = np.mean(cross_val_score(model, XX, yy, cv=5))\n",
    "    print(title, \"Accuracy:\",acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------------------------- f =  300 ------------------------------\n",
      "\n",
      "========= k-nearest neighbour (with f= 300 features): \n",
      "x2 accuracy is: 0.6602965907353615\n",
      "[[  22  851   22]\n",
      " [  47 4018  202]\n",
      " [   8 1092  279]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.29      0.02      0.05       895\n",
      "     neutral       0.67      0.94      0.79      4267\n",
      "    positive       0.55      0.20      0.30      1379\n",
      "\n",
      "    accuracy                           0.66      6541\n",
      "   macro avg       0.50      0.39      0.38      6541\n",
      "weighted avg       0.60      0.66      0.58      6541\n",
      "\n",
      "['neutral' 'neutral' 'neutral' ... 'neutral' 'neutral' 'positive']\n",
      "k-nearest neighbour Accuracy: 0.6241621945139255\n"
     ]
    }
   ],
   "source": [
    "# KNN chisq tfidf\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(strip_accents='ascii', ngram_range=(1,1), lowercase=True)\n",
    "\n",
    "#Build the feature set (vocabulary) and vectorise the Tarin dataset using TFIDF\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train_raw)\n",
    "\n",
    "#Use the feature set (vocabulary) from Train to vectorise the Test dataset \n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test_raw)\n",
    "\n",
    "models = [KNeighborsClassifier(n_neighbors=100, weights='distance')]\n",
    "titles = ['k-nearest neighbour']\n",
    "\n",
    "\n",
    "\n",
    "for f in [300]:\n",
    "    print('\\n--------------------------------------- f = ', f,'------------------------------')\n",
    "    x2 = SelectKBest(chi2, k=f)\n",
    "    x2.fit(X_train_tfidf,Y_train)\n",
    "    X_train_x2 = x2.transform(X_train_tfidf)\n",
    "    X_test_x2 = x2.transform(X_test_tfidf)\n",
    "\n",
    "    knnpredictions = []\n",
    "\n",
    "    Xs = [(X_train_x2, X_test_x2)]\n",
    "    X_names = ['x2']\n",
    "    for title, model in zip(titles, models):\n",
    "        print('\\n=========',title, '(with f=',f,'features): ')\n",
    "        for X_name, X in zip(X_names, Xs):\n",
    "            X_train_t, X_test_t = X\n",
    "            model.fit(X_train_t, Y_train)\n",
    "            y_test_predict = model.predict(X_test_t)\n",
    "            knnpredictions = y_test_predict\n",
    "            accuracy =  accuracy_score(Y_test, y_test_predict)\n",
    "            print(X_name, 'accuracy is:',  accuracy)\n",
    "            print(confusion_matrix(Y_test, y_test_predict, labels=[\"negative\", \"neutral\", \"positive\"]))\n",
    "            print(classification_report(Y_test, y_test_predict, labels=[\"negative\", \"neutral\", \"positive\"]))\n",
    "\n",
    "print(knnpredictions)\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import numpy as np\n",
    "\n",
    "XX = [x[0] for x in train_data_full[['text']].values]\n",
    "yy = [x[0] for x in train_data_full[['sentiment']].values]\n",
    "XX = tfidf_vectorizer.fit_transform(XX)\n",
    "\n",
    "\n",
    "for title, model in zip(titles, models):\n",
    "    acc = np.mean(cross_val_score(model, XX, yy, cv=5))\n",
    "    print(title, \"Accuracy:\",acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total accuracy is: 0.6800183458186821\n"
     ]
    }
   ],
   "source": [
    "# Combining all 4 classifiers\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "finalpredict = []\n",
    "for i in range(len(svmpredictions)):\n",
    "    predictcombine = defaultdict(int)\n",
    "    predictcombine[svmpredictions[i]]+=1\n",
    "    predictcombine[mnbpredictions[i]]+=1\n",
    "    predictcombine[logisticpredictions[i]]+=1\n",
    "    predictcombine[knnpredictions[i]]+=1\n",
    "    count = 0\n",
    "    final = \" \"\n",
    "    for key,value in predictcombine.items():\n",
    "        if value > count:\n",
    "            count = value\n",
    "            final = key\n",
    "    finalpredict.append(final)\n",
    "\n",
    "#print(predictcombine)\n",
    "#print(finalpredict)\n",
    "accuracy =  accuracy_score(Y_test, finalpredict)\n",
    "print('Total accuracy is:',  accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train length: 15261\n",
      "Test length: 6099\n",
      "['neutral' 'neutral' 'neutral' ... 'neutral' 'neutral' 'negative']\n",
      "['neutral' 'neutral' 'neutral' ... 'neutral' 'positive' 'negative']\n",
      "['neutral' 'neutral' 'neutral' ... 'neutral' 'positive' 'negative']\n",
      "['positive' 'neutral' 'neutral' ... 'neutral' 'neutral' 'neutral']\n"
     ]
    }
   ],
   "source": [
    "# This code block is for generating kaggle output\n",
    "# copied all the code here for ease of access \n",
    "# simply clicking run will make kaggle csv prediction file\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "train_data_full = pd.read_csv(\"Train.csv\", sep=',')\n",
    "\n",
    "trainrows = int(0.7*len(train_data_full))\n",
    "\n",
    "train_data = pd.read_csv(\"Train.csv\", sep=',', nrows=trainrows)\n",
    "\n",
    "\n",
    "test_data = pd.read_csv(\"Test.csv\", sep=',')\n",
    "\n",
    "#separating instance and label for Train\n",
    "X_train_raw = [x[0] for x in train_data[['text']].values]\n",
    "Y_train = [x[0] for x in train_data[['sentiment']].values]\n",
    "\n",
    "#check the result\n",
    "print(\"Train length:\",len(X_train_raw))\n",
    "\n",
    "#separating instance and label for Test\n",
    "X_test_raw = [x[0] for x in test_data[['text']].values]\n",
    "\n",
    "#check the result\n",
    "print(\"Test length:\",len(X_test_raw))\n",
    "\n",
    "# MultinomialNB BoW\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "BoW_vectorizer = CountVectorizer(ngram_range=(1,2), strip_accents='ascii', lowercase=False)\n",
    "\n",
    "#Build the feature set (vocabulary) and vectorise the Train dataset using BoW\n",
    "X_train_BoW = BoW_vectorizer.fit_transform(X_train_raw)\n",
    "\n",
    "#Use the feature set (vocabulary) from Train to vectorise the Test dataset \n",
    "X_test_BoW = BoW_vectorizer.transform(X_test_raw)\n",
    "\n",
    "models = [MultinomialNB(alpha=1,fit_prior=True)]\n",
    "titles = ['MNB']\n",
    "\n",
    "mnbpredictions = []\n",
    "\n",
    "Xs = [(X_train_BoW, X_test_BoW)]\n",
    "X_names = ['BoW']\n",
    "for title, model in zip(titles, models):\n",
    "    for X_name, X in zip(X_names, Xs):\n",
    "        X_train_t, X_test_t = X\n",
    "        model.fit(X_train_t, Y_train)\n",
    "        y_test_predict = model.predict(X_test_t)\n",
    "        #print(y_test_predict)\n",
    "        mnbpredictions = y_test_predict\n",
    "\n",
    "\n",
    "print(mnbpredictions)\n",
    "\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(strip_accents='ascii', ngram_range=(1,1), lowercase=True)\n",
    "\n",
    "#Build the feature set (vocabulary) and vectorise the Tarin dataset using TFIDF\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train_raw)\n",
    "\n",
    "#Use the feature set (vocabulary) from Train to vectorise the Test dataset \n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test_raw)\n",
    "\n",
    "models = [LogisticRegression(max_iter = 1000,multi_class='multinomial',solver='saga',C=1,penalty='l1')]\n",
    "titles = ['Logistic Regression',]\n",
    "\n",
    "logisticpredictions = []\n",
    "\n",
    "Xs = [(X_train_tfidf, X_test_tfidf)]\n",
    "X_names = ['tfidf']\n",
    "for title, model in zip(titles, models):\n",
    "    for X_name, X in zip(X_names, Xs):\n",
    "        X_train_t, X_test_t = X\n",
    "        model.fit(X_train_t, Y_train)\n",
    "        y_test_predict = model.predict(X_test_t)\n",
    "        logisticpredictions = y_test_predict\n",
    "\n",
    "print(logisticpredictions)\n",
    "\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "\n",
    "svmpredictions = []\n",
    "\n",
    "Xs = [(X_train_tfidf, X_test_tfidf)]\n",
    "X_names = ['tfidf']\n",
    "for title, model in zip(titles, models):\n",
    "    for X_name, X in zip(X_names, Xs):\n",
    "        X_train_t, X_test_t = X\n",
    "        model.fit(X_train_t, Y_train)\n",
    "        y_test_predict = model.predict(X_test_t)\n",
    "        svmpredictions = y_test_predict\n",
    "\n",
    "\n",
    "print(svmpredictions)\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "\n",
    "models = [KNeighborsClassifier(n_neighbors=100, weights='distance')]\n",
    "titles = ['k-nearest neighbour']\n",
    "\n",
    "\n",
    "for f in [300]:\n",
    "    \n",
    "    x2 = SelectKBest(chi2, k=f)\n",
    "    x2.fit(X_train_tfidf,Y_train)\n",
    "    X_train_x2 = x2.transform(X_train_tfidf)\n",
    "    X_test_x2 = x2.transform(X_test_tfidf)\n",
    "\n",
    "    knnpredictions = []\n",
    "\n",
    "    Xs = [(X_train_x2, X_test_x2)]\n",
    "    X_names = ['x2']\n",
    "    for title, model in zip(titles, models):\n",
    "        \n",
    "        for X_name, X in zip(X_names, Xs):\n",
    "            X_train_t, X_test_t = X\n",
    "            model.fit(X_train_t, Y_train)\n",
    "            y_test_predict = model.predict(X_test_t)\n",
    "            knnpredictions = y_test_predict\n",
    "\n",
    "\n",
    "print(knnpredictions)\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "finalpredict = []\n",
    "for i in range(len(svmpredictions)):\n",
    "    predictcombine = defaultdict(int)\n",
    "    predictcombine[svmpredictions[i]]+=1\n",
    "    predictcombine[mnbpredictions[i]]+=1\n",
    "    predictcombine[logisticpredictions[i]]+=1\n",
    "    #predictcombine[knnpredictions[i]]+=1\n",
    "    count = 0\n",
    "    final = \" \"\n",
    "    for key,value in predictcombine.items():\n",
    "        if value > count:\n",
    "            count = value\n",
    "            final = key\n",
    "    finalpredict.append(final)\n",
    "\n",
    "    \n",
    "import csv  \n",
    "\n",
    "header = ['id','sentiment']\n",
    "\n",
    "with open('1170385.csv', 'w', encoding='UTF8', newline='') as f:\n",
    "    writer = csv.writer(f)\n",
    "\n",
    "    writer.writerow(header)\n",
    "\n",
    "    for i in range(len(test_data)):\n",
    "        data = []\n",
    "        data.append(test_data.iloc[i,0])\n",
    "        data.append(finalpredict[i])\n",
    "        writer.writerow(data)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b0d9a8e83623c6a29a609e83f21b65ce4862cc96e34fdcc611b3d9f5ef451c1a"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
